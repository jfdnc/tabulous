Command: llm
Help Output:
Usage: llm [OPTIONS] COMMAND [ARGS]...

  Access large language models from the command-line

  Documentation: https://llm.datasette.io/

  To get started, obtain an OpenAI key and set it like this:

      $ llm keys set openai
      Enter key: ...

  Then execute a prompt like this:

      llm 'Five outrageous names for a pet pelican'

Options:
  --version  Show the version and exit.
  --help     Show this message and exit.

Commands:
  prompt*       Execute a prompt
  aliases       Manage model aliases
  chat          Hold an ongoing chat with a model.
  collections   View and manage collections of embeddings
  embed         Embed text and store or return the result
  embed-models  Manage available embedding models
  embed-multi   Store embeddings for multiple strings at once
  install       Install packages from PyPI into the same environment as LLM
  keys          Manage stored API keys for different models
  logs          Tools for exploring logged prompts and responses
  models        Manage available models
  openai        Commands for working directly with the OpenAI API
  plugins       List installed plugins
  similar       Return top N similar IDs from a collection
  templates     Manage stored prompt templates
  uninstall     Uninstall Python packages from the LLM environment
LLM Response:
Based on the provided `--help` output from the `llm` command, here is a structured list of potential sub-commands and options:

### Options:
- `--version`  Show the version and exit.
- `--help`     Show this message and exit.

### Commands:
1. **prompt**
   - Execute a prompt

2. **aliases**
   - Manage model aliases

3. **chat**
   - Hold an ongoing chat with a model.

4. **collections**
   - View and manage collections of embeddings

5. **embed**
   - Embed text and store or return the result

6. **embed-models**
   - Manage available embedding models

7. **embed-multi**
   - Store embeddings for multiple strings at once

8. **install**
   - Install packages from PyPI into the same environment as LLM

9. **keys**
   - Manage stored API keys for different models

10. **logs**
    - Tools for exploring logged prompts and responses

11. **models**
    - Manage available models

12. **openai**
    - Commands for working directly with the OpenAI API

13. **plugins**
    - List installed plugins

14. **similar**
    - Return top N similar IDs from a collection

15. **templates**
    - Manage stored prompt templates

16. **uninstall**
    - Uninstall Python packages from the LLM environment

This structured list clarifies the available options and commands you can use with the `llm` command.
------------------------------------
Command: llm
Help Output:
Usage: llm [OPTIONS] COMMAND [ARGS]...

  Access large language models from the command-line

  Documentation: https://llm.datasette.io/

  To get started, obtain an OpenAI key and set it like this:

      $ llm keys set openai
      Enter key: ...

  Then execute a prompt like this:

      llm 'Five outrageous names for a pet pelican'

Options:
  --version  Show the version and exit.
  --help     Show this message and exit.

Commands:
  prompt*       Execute a prompt
  aliases       Manage model aliases
  chat          Hold an ongoing chat with a model.
  collections   View and manage collections of embeddings
  embed         Embed text and store or return the result
  embed-models  Manage available embedding models
  embed-multi   Store embeddings for multiple strings at once
  install       Install packages from PyPI into the same environment as LLM
  keys          Manage stored API keys for different models
  logs          Tools for exploring logged prompts and responses
  models        Manage available models
  openai        Commands for working directly with the OpenAI API
  plugins       List installed plugins
  similar       Return top N similar IDs from a collection
  templates     Manage stored prompt templates
  uninstall     Uninstall Python packages from the LLM environment
LLM Response:
Here is a structured list of potential sub-commands and options for the `llm` command based on the provided --help output:

### Options
- `--version` : Show the version and exit.
- `--help` : Show this message and exit.

### Commands
1. **prompt**: Execute a prompt.
2. **aliases**: Manage model aliases.
3. **chat**: Hold an ongoing chat with a model.
4. **collections**: View and manage collections of embeddings.
5. **embed**: Embed text and store or return the result.
6. **embed-models**: Manage available embedding models.
7. **embed-multi**: Store embeddings for multiple strings at once.
8. **install**: Install packages from PyPI into the same environment as LLM.
9. **keys**: Manage stored API keys for different models.
10. **logs**: Tools for exploring logged prompts and responses.
11. **models**: Manage available models.
12. **openai**: Commands for working directly with the OpenAI API.
13. **plugins**: List installed plugins.
14. **similar**: Return top N similar IDs from a collection.
15. **templates**: Manage stored prompt templates.
16. **uninstall**: Uninstall Python packages from the LLM environment. 

This structured list summarizes the available options and commands for the `llm` command, enabling easier navigation and usage of the tool.
------------------------------------
